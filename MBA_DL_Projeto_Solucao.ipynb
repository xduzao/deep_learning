{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce13d08",
   "metadata": {},
   "source": [
    "\n",
    "# Projeto Integrado — Deep Learning (QuantumFinance) — **Solução em CSV**\n",
    "\n",
    "Este notebook implementa a solução solicitada no enunciado:\n",
    "- Treinar modelos **CNN 1D** e **LSTM** com **TensorFlow/Keras** usando os arquivos `treino.csv` e `teste.csv` para **cada um dos 4 ativos**.\n",
    "- **Relatar métricas no conjunto de teste**: **acurácia**, **matriz de confusão**, **precision** e **recall**.\n",
    "- **Backtest (opcional)** simples, aplicando o sinal previsto do dia T no retorno de T+1.\n",
    "- **Salvar predições** por ativo/modelo em `output/` e gerar um **resumo consolidado**.\n",
    "\n",
    "> Estrutura esperada de diretórios (exemplo):\n",
    "```\n",
    "bases/\n",
    " ├─ BBAS3SA/\n",
    " │   ├─ treino.csv\n",
    " │   ├─ teste.csv\n",
    " │   └─ visualizacao.html   (não modificado pelo notebook)\n",
    " ├─ VALE3SA/\n",
    " │   ├─ treino.csv\n",
    " │   ├─ teste.csv\n",
    " │   └─ visualizacao.html\n",
    " ├─ PETR4SA/\n",
    " └─ CSNA3SA/\n",
    "output/   (será criado se não existir)\n",
    "```\n",
    "\n",
    "> Observação: o arquivo `visualizacao.html` **não é alterado**. Caso deseje EDA adicional,\n",
    "> o notebook pode salvar um `eda_auto_<TICKER>.html` separado, sem sobrescrever o original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c0d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================== SETUP ==================\n",
    "import os, re, warnings, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# TensorFlow / Keras\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"TensorFlow/Keras não está disponível neste ambiente. \"\n",
    "        \"Instale com `pip install tensorflow` e reinicie o kernel.\\n\"\n",
    "        f\"Erro original: {e}\"\n",
    "    )\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Caminhos principais (ajuste se necessário)\n",
    "DATA_ROOT = Path(\"bases\")\n",
    "OUT_ROOT  = Path(\"output\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Aliases de colunas para autodetecção\n",
    "LABEL_ALIASES = [\"label\", \"rotulo\", \"rótulo\", \"target\", \"y\"]\n",
    "DATE_ALIASES  = [\"date\", \"data\", \"day\", \"dia\"]\n",
    "CLOSE_ALIASES = [\"close\", \"fechamento\", \"close_price\", \"preco_fechamento\", \"preço_fechamento\"]\n",
    "\n",
    "WINDOW = 15  # janela de lags D-1...D-15\n",
    "EPOCHS = 25\n",
    "BATCH  = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e19104",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================== FUNÇÕES AUXILIARES ==================\n",
    "def find_col(cols, aliases):\n",
    "    cols_norm = [c.strip().lower() for c in cols]\n",
    "    for a in aliases:\n",
    "        a_norm = a.lower()\n",
    "        # igualdade exata\n",
    "        for c in cols:\n",
    "            if c.strip().lower() == a_norm:\n",
    "                return c\n",
    "        # contém alias\n",
    "        for c in cols:\n",
    "            if a_norm in c.strip().lower():\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "def autodiscover_pairs(root: Path):\n",
    "    \"\"\"\n",
    "    Descobre subpastas com treino.csv e teste.csv.\n",
    "    Retorna dict: {TICKER: {'train': Path, 'test': Path}}\n",
    "    \"\"\"\n",
    "    pairs = {}\n",
    "    for d in sorted([p for p in root.iterdir() if p.is_dir()]):\n",
    "        tr = d/\"treino.csv\"\n",
    "        te = d/\"teste.csv\"\n",
    "        if tr.exists() and te.exists():\n",
    "            pairs[d.name.upper()] = {\"train\": tr, \"test\": te}\n",
    "    return pairs\n",
    "\n",
    "def load_pair(train_path: Path, test_path: Path):\n",
    "    df_tr = pd.read_csv(train_path)\n",
    "    df_te = pd.read_csv(test_path)\n",
    "    return df_tr, df_te\n",
    "\n",
    "def prepare_xy(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Detecta coluna de rótulo e 15 features (lags) numéricas.\n",
    "    Normaliza (StandardScaler) e devolve X em formato (N, 15, 1) para CNN/LSTM.\n",
    "    \"\"\"\n",
    "    cols = list(df.columns)\n",
    "    label_col = find_col(cols, LABEL_ALIASES)\n",
    "    date_col  = find_col(cols, DATE_ALIASES)\n",
    "    close_col = find_col(cols, CLOSE_ALIASES)\n",
    "\n",
    "    if label_col is None:\n",
    "        raise ValueError(\"Não foi possível detectar a coluna de rótulo (use label/rotulo/target/y).\"\n",
    "\n",
    "        )\n",
    "    # Heurística: use as últimas 15 colunas numéricas (exceto label)\n",
    "    feat_cols = [c for c in cols if c != label_col and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if len(feat_cols) < 15:\n",
    "        raise ValueError(f\"Menos de 15 features numéricas encontradas. Colunas numéricas: {feat_cols}\")\n",
    "    feat_cols = feat_cols[-15:]\n",
    "\n",
    "    X = df[feat_cols].values\n",
    "    y = df[label_col].astype(int).values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X3 = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "    meta = {\"label\": label_col, \"date\": date_col, \"close\": close_col, \"features\": feat_cols}\n",
    "    return X3, y, meta\n",
    "\n",
    "def build_cnn1d(input_shape):\n",
    "    m = keras.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Conv1D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.Conv1D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"tanh\")  # saída contínua [-1,1]\n",
    "    ])\n",
    "    m.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mse\")\n",
    "    return m\n",
    "\n",
    "def build_lstm(input_shape):\n",
    "    m = keras.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.LSTM(32, return_sequences=False),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"tanh\")\n",
    "    ])\n",
    "    m.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mse\")\n",
    "    return m\n",
    "\n",
    "def evaluate_on_test(model, Xte, yte, ticker, model_name, close_series=None):\n",
    "    # contínuo -> classe {-1,+1}\n",
    "    y_pred_cont = model.predict(Xte, verbose=0).ravel()\n",
    "    y_pred = np.where(y_pred_cont >= 0, 1, -1)\n",
    "\n",
    "    acc = accuracy_score(yte, y_pred)\n",
    "    cm  = confusion_matrix(yte, y_pred, labels=[-1, 1])\n",
    "    pre, rec, f1, sup = precision_recall_fscore_support(\n",
    "        yte, y_pred, labels=[-1,1], zero_division=0\n",
    "    )\n",
    "    report = classification_report(yte, y_pred, target_names=[\"SELL(-1)\", \"BUY(+1)\"], digits=4)\n",
    "\n",
    "    # Backtest simples\n",
    "    bt = None\n",
    "    if close_series is not None:\n",
    "        close = close_series.astype(float).values\n",
    "        ret_next = np.zeros_like(close, dtype=float)\n",
    "        safe = np.where(close[:-1]==0, 1e-12, close[:-1])\n",
    "        ret_next[:-1] = (close[1:] - close[:-1]) / safe\n",
    "        pos = y_pred.astype(float)\n",
    "        strat_ret = np.zeros_like(ret_next)\n",
    "        strat_ret[:-1] = pos[:-1] * ret_next[:-1]\n",
    "        bt = {\n",
    "            \"bh_cum\": float(np.prod(1+ret_next) - 1),\n",
    "            \"model_cum\": float(np.prod(1+strat_ret) - 1),\n",
    "            \"bh_avg\": float(np.mean(ret_next)),\n",
    "            \"model_avg\": float(np.mean(strat_ret)),\n",
    "            \"bh_vol\": float(np.std(ret_next)),\n",
    "            \"model_vol\": float(np.std(strat_ret)),\n",
    "        }\n",
    "\n",
    "    # Salvar predições\n",
    "    out_csv = Path(\"output\") / f\"predicoes_{ticker}_{model_name}.csv\"\n",
    "    out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    import pandas as pd\n",
    "    pd.DataFrame({\"y_true\": yte, \"y_pred\": y_pred}).to_csv(out_csv, index=False)\n",
    "\n",
    "    # Retornar dicionário para consolidação\n",
    "    return {\n",
    "        \"ticker\": ticker,\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision_-1\": pre[0], \"recall_-1\": rec[0],\n",
    "        \"precision_+1\": pre[1], \"recall_+1\": rec[1],\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"report\": report,\n",
    "        \"backtest\": bt,\n",
    "        \"pred_csv\": str(out_csv)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ef1f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ativos detectados:\n",
      "- BBAS3SA: bases\\BBAS3SA\\treino.csv / bases\\BBAS3SA\\teste.csv\n",
      "- CSNA3SA: bases\\CSNA3SA\\treino.csv / bases\\CSNA3SA\\teste.csv\n",
      "- PETRA4SA: bases\\PETRA4SA\\treino.csv / bases\\PETRA4SA\\teste.csv\n",
      "- VALE3SA: bases\\VALE3SA\\treino.csv / bases\\VALE3SA\\teste.csv\n",
      "\n",
      "=== BBAS3SA ===\n",
      "\n",
      "=== CSNA3SA ===\n",
      "\n",
      "=== PETRA4SA ===\n",
      "\n",
      "=== VALE3SA ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision(-1)</th>\n",
       "      <th>Recall(-1)</th>\n",
       "      <th>Precision(+1)</th>\n",
       "      <th>Recall(+1)</th>\n",
       "      <th>PredicoesCSV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBAS3SA</td>\n",
       "      <td>CNN1D</td>\n",
       "      <td>0.845570</td>\n",
       "      <td>0.909385</td>\n",
       "      <td>0.815675</td>\n",
       "      <td>0.776014</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>output\\predicoes_BBAS3SA_CNN1D.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBAS3SA</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.752743</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.725689</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>output\\predicoes_BBAS3SA_LSTM.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSNA3SA</td>\n",
       "      <td>CNN1D</td>\n",
       "      <td>0.852445</td>\n",
       "      <td>0.840637</td>\n",
       "      <td>0.920058</td>\n",
       "      <td>0.872979</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>output\\predicoes_CSNA3SA_CNN1D.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSNA3SA</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.844013</td>\n",
       "      <td>0.892356</td>\n",
       "      <td>0.831395</td>\n",
       "      <td>0.787156</td>\n",
       "      <td>0.861446</td>\n",
       "      <td>output\\predicoes_CSNA3SA_LSTM.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PETRA4SA</td>\n",
       "      <td>CNN1D</td>\n",
       "      <td>0.807980</td>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.805508</td>\n",
       "      <td>0.816856</td>\n",
       "      <td>0.810289</td>\n",
       "      <td>output\\predicoes_PETRA4SA_CNN1D.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PETRA4SA</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.791355</td>\n",
       "      <td>0.818533</td>\n",
       "      <td>0.729776</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.848875</td>\n",
       "      <td>output\\predicoes_PETRA4SA_LSTM.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VALE3SA</td>\n",
       "      <td>CNN1D</td>\n",
       "      <td>0.831255</td>\n",
       "      <td>0.781073</td>\n",
       "      <td>0.920133</td>\n",
       "      <td>0.903030</td>\n",
       "      <td>0.742525</td>\n",
       "      <td>output\\predicoes_VALE3SA_CNN1D.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VALE3SA</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.718204</td>\n",
       "      <td>0.652681</td>\n",
       "      <td>0.931780</td>\n",
       "      <td>0.881159</td>\n",
       "      <td>0.504983</td>\n",
       "      <td>output\\predicoes_VALE3SA_LSTM.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ticker Modelo  Accuracy  Precision(-1)  Recall(-1)  Precision(+1)  \\\n",
       "0   BBAS3SA  CNN1D  0.845570       0.909385    0.815675       0.776014   \n",
       "1   BBAS3SA   LSTM  0.752743       0.827815    0.725689       0.674699   \n",
       "2   CSNA3SA  CNN1D  0.852445       0.840637    0.920058       0.872979   \n",
       "3   CSNA3SA   LSTM  0.844013       0.892356    0.831395       0.787156   \n",
       "4  PETRA4SA  CNN1D  0.807980       0.798635    0.805508       0.816856   \n",
       "5  PETRA4SA   LSTM  0.791355       0.818533    0.729776       0.770803   \n",
       "6   VALE3SA  CNN1D  0.831255       0.781073    0.920133       0.903030   \n",
       "7   VALE3SA   LSTM  0.718204       0.652681    0.931780       0.881159   \n",
       "\n",
       "   Recall(+1)                         PredicoesCSV  \n",
       "0    0.887097   output\\predicoes_BBAS3SA_CNN1D.csv  \n",
       "1    0.790323    output\\predicoes_BBAS3SA_LSTM.csv  \n",
       "2    0.759036   output\\predicoes_CSNA3SA_CNN1D.csv  \n",
       "3    0.861446    output\\predicoes_CSNA3SA_LSTM.csv  \n",
       "4    0.810289  output\\predicoes_PETRA4SA_CNN1D.csv  \n",
       "5    0.848875   output\\predicoes_PETRA4SA_LSTM.csv  \n",
       "6    0.742525   output\\predicoes_VALE3SA_CNN1D.csv  \n",
       "7    0.504983    output\\predicoes_VALE3SA_LSTM.csv  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OK] Consolidado salvo em: output\\resultados_consolidados.csv\n",
      "[OK] Relatório Markdown salvo em: output\\RELATORIO_RESULTADOS.md\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================== EXECUÇÃO PRINCIPAL ==================\n",
    "pairs = autodiscover_pairs(DATA_ROOT)\n",
    "if not pairs:\n",
    "    raise SystemExit(f\"Nenhuma pasta encontrada em {DATA_ROOT.resolve()} com treino.csv/teste.csv.\")\n",
    "\n",
    "print(\"Ativos detectados:\")\n",
    "for t, p in pairs.items():\n",
    "    print(f\"- {t}: {p['train']} / {p['test']}\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for ticker, paths in pairs.items():\n",
    "    print(f\"\\n=== {ticker} ===\")\n",
    "    df_tr, df_te = load_pair(paths[\"train\"], paths[\"test\"])\n",
    "\n",
    "    # Preparar dados\n",
    "    Xtr, ytr, meta_tr = prepare_xy(df_tr)\n",
    "    Xte, yte, meta_te = prepare_xy(df_te)\n",
    "    assert meta_tr[\"features\"] == meta_te[\"features\"], \"Features de treino e teste não coincidem.\"\n",
    "\n",
    "    # CNN 1D\n",
    "    cnn = build_cnn1d(Xtr.shape[1:])\n",
    "    hist1 = cnn.fit(Xtr, ytr, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH, verbose=0)\n",
    "    res1 = evaluate_on_test(cnn, Xte, yte, ticker, \"CNN1D\",\n",
    "                            close_series=df_te[meta_te[\"close\"]] if meta_te[\"close\"] else None)\n",
    "    results.append(res1)\n",
    "\n",
    "    # LSTM\n",
    "    lstm = build_lstm(Xtr.shape[1:])\n",
    "    hist2 = lstm.fit(Xtr, ytr, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH, verbose=0)\n",
    "    res2 = evaluate_on_test(lstm, Xte, yte, ticker, \"LSTM\",\n",
    "                            close_series=df_te[meta_te[\"close\"]] if meta_te[\"close\"] else None)\n",
    "    results.append(res2)\n",
    "\n",
    "# ================== CONSOLIDADO ==================\n",
    "import pandas as pd, json\n",
    "res_df = pd.DataFrame([{\n",
    "    \"Ticker\": r[\"ticker\"],\n",
    "    \"Modelo\": r[\"model\"],\n",
    "    \"Accuracy\": r[\"accuracy\"],\n",
    "    \"Precision(-1)\": r[\"precision_-1\"],\n",
    "    \"Recall(-1)\": r[\"recall_-1\"],\n",
    "    \"Precision(+1)\": r[\"precision_+1\"],\n",
    "    \"Recall(+1)\": r[\"recall_+1\"],\n",
    "    \"PredicoesCSV\": r[\"pred_csv\"]\n",
    "} for r in results]).sort_values([\"Ticker\",\"Modelo\"])\n",
    "\n",
    "display(res_df)\n",
    "\n",
    "# Salva CSV consolidado\n",
    "consol_csv = Path(\"output\") / \"resultados_consolidados.csv\"\n",
    "res_df.to_csv(consol_csv, index=False)\n",
    "print(f\"\\n[OK] Consolidado salvo em: {consol_csv}\")\n",
    "\n",
    "# Opcional: salvar relatório simples em Markdown\n",
    "md_lines = [\"# Resultados — Projeto Integrado (CSV)\\n\"]\n",
    "for r in results:\n",
    "    md_lines.append(f\"## {r['ticker']} — {r['model']}\")\n",
    "    md_lines.append(f\"- Accuracy: {r['accuracy']:.4f}\")\n",
    "    md_lines.append(f\"- Predições: `{r['pred_csv']}`\")\n",
    "    md_lines.append(\"\\n**Classification report:**\\n\")\n",
    "    md_lines.append(\"```\\n\" + r[\"report\"] + \"\\n```\")\n",
    "    if r[\"backtest\"]:\n",
    "        md_lines.append(\"**Backtest (retornos cumulativos aproximados):**\")\n",
    "        md_lines.append(\"```\\n\" + json.dumps(r[\"backtest\"], indent=2) + \"\\n```\")\n",
    "    md_lines.append(\"\\n\")\n",
    "md_path = Path(\"output\") / \"RELATORIO_RESULTADOS.md\"\n",
    "md_path.write_text(\"\\n\".join(md_lines), encoding=\"utf-8\")\n",
    "print(f\"[OK] Relatório Markdown salvo em: {md_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c1f289a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ================== EDA AUTOMÁTICA (gera eda_auto_<TICKER>.html) ==================\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Não altera o visualizacao.html fornecido. Salva um arquivo novo por pasta.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msubplots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_subplots\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================== EDA AUTOMÁTICA (gera eda_auto_<TICKER>.html) ==================\n",
    "# Não altera o visualizacao.html fornecido. Salva um arquivo novo por pasta.\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import plot as plot_offline\n",
    "\n",
    "def _detect_cols_for_eda(df):\n",
    "    label = next((c for c in df.columns if str(c).lower() in {\"label\",\"rotulo\",\"rótulo\",\"target\",\"y\"}), None)\n",
    "    date  = next((c for c in df.columns if str(c).lower() in {\"date\",\"data\",\"day\",\"dia\"}), None)\n",
    "    close = next((c for c in df.columns if \"close\" in str(c).lower() or \"fech\" in str(c).lower()), None)\n",
    "    feats = [c for c in df.columns if c != label and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    feats = feats[-15:] if len(feats) >= 15 else feats\n",
    "    return label, date, close, feats\n",
    "\n",
    "def gerar_eda_html_por_ticker(DATA_ROOT=DATA_ROOT):\n",
    "    for d in sorted([p for p in DATA_ROOT.iterdir() if p.is_dir()]):\n",
    "        train = d / \"treino.csv\"; test = d / \"teste.csv\"\n",
    "        if not (train.exists() and test.exists()):\n",
    "            continue\n",
    "        df_tr = pd.read_csv(train); df_te = pd.read_csv(test)\n",
    "        label, date, close, feats = _detect_cols_for_eda(df_tr)\n",
    "        figs = []\n",
    "\n",
    "        # 1) Distribuição do rótulo\n",
    "        if label:\n",
    "            figs.append(px.histogram(df_tr, x=label, title=f\"{d.name} · Distribuição do rótulo (Treino)\"))\n",
    "            figs.append(px.histogram(df_te, x=label, title=f\"{d.name} · Distribuição do rótulo (Teste)\"))\n",
    "\n",
    "        # 2) Série de fechamento (se existir)\n",
    "        if close:\n",
    "            x_tr = df_tr[date] if (date and date in df_tr.columns) else df_tr.index\n",
    "            x_te = df_te[date] if (date and date in df_te.columns) else df_te.index\n",
    "            fig_close = make_subplots(rows=2, cols=1, shared_xaxes=False,\n",
    "                                      subplot_titles=(\"Treino - Close\", \"Teste - Close\"))\n",
    "            fig_close.add_trace(go.Scatter(x=x_tr, y=df_tr[close], mode=\"lines\", name=\"Close (Treino)\"), row=1, col=1)\n",
    "            fig_close.add_trace(go.Scatter(x=x_te, y=df_te[close], mode=\"lines\", name=\"Close (Teste)\"), row=2, col=1)\n",
    "            fig_close.update_layout(title_text=f\"{d.name} · Série de Fechamento\")\n",
    "            figs.append(fig_close)\n",
    "\n",
    "        # 3) Correlação entre features\n",
    "        if len(feats) >= 2:\n",
    "            corr = df_tr[feats].corr()\n",
    "            figs.append(go.Figure(data=go.Heatmap(z=corr.values, x=corr.columns, y=corr.index)).update_layout(\n",
    "                title=f\"{d.name} · Correlação (treino)\"\n",
    "            ))\n",
    "\n",
    "        # 4) Scatter-matrix (últimas 3 features vs label)\n",
    "        if label and len(feats) >= 3:\n",
    "            last3 = feats[-3:]\n",
    "            mdf = df_tr[last3 + [label]].copy()\n",
    "            mdf[label] = mdf[label].astype(str)\n",
    "            figs.append(px.scatter_matrix(mdf, dimensions=last3, color=label,\n",
    "                                          title=f\"{d.name} · Scatter matrix (treino)\"))\n",
    "\n",
    "        # salvar HTML concatenado\n",
    "        out_html = d / f\"eda_auto_{d.name.upper()}.html\"\n",
    "        parts = []\n",
    "        for i, f in enumerate(figs, 1):\n",
    "            parts.append(plot_offline(f, include_plotlyjs=(i==1), output_type=\"div\"))\n",
    "        html = \"<html><head><meta charset='utf-8'><title>EDA Auto {}</title></head><body>{}</body></html>\".format(\n",
    "            d.name.upper(), \"\\n<hr/>\\n\".join(parts)\n",
    "        )\n",
    "        out_html.write_text(html, encoding=\"utf-8\")\n",
    "        print(f\"[OK] EDA salvo: {out_html}\")\n",
    "\n",
    "# Descomente para rodar quando quiser gerar os HTMLs\n",
    "# gerar_eda_html_por_ticker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ced577",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================== COMPARATIVO DESTACADO (CNN 1D vs LSTM) ==================\n",
    "# Usa o 'res_df' criado na execução principal.\n",
    "import pandas as pd\n",
    "\n",
    "if 'res_df' in globals():\n",
    "    pivot = res_df.pivot(index=\"Ticker\", columns=\"Modelo\", values=\"Accuracy\")\n",
    "    styled = pivot.style.highlight_max(axis=1)\n",
    "    html_path = Path(\"output\") / \"comparativo_modelos.html\"\n",
    "    styled.to_html(html_path)\n",
    "    display(pivot)\n",
    "    print(f\"[OK] Comparativo salvo em: {html_path}\")\n",
    "else:\n",
    "    print(\"Execute a seção principal primeiro para criar 'res_df'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
